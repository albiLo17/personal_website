<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Publications | Alberta Longhini </title> <meta name="author" content="Alberta Longhini"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/al-folio/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/al-folio/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/al-folio/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/al-folio/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://albilo17.github.io/al-folio/publications/"> <script src="/al-folio/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/al-folio/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/al-folio/"> <span class="font-weight-bold">Alberta</span> Longhini </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/al-folio/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/al-folio/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/al-folio/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications</h1> <p class="post-description"></p> </header> <article> <h4><a href="https://scholar.google.com/citations?user=gwFVvsQAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Google Scholar</a></h4> <script>function showhide(e){var l=document.getElementById(e);"none"===l.style.display?l.style.display="block":l.style.display="none"}</script> <table cellpadding="10" width="100%"> <tr> <td width="200" height="100"> <img src="../assets/images/radar_chart2.png" img="" width="250"> </td> <td> <h6><a href="https://arxiv.org/pdf/2209.08996.pdf" rel="external nofollow noopener" target="_blank">Standardization of Cloth Objects and its Relevance in Robotic Manipulation</a></h6> <div style="line-height:50%;"> <br> </div> <div style="font-size:medium"> <nobr>Garcia-Camacho Irene,</nobr> <nobr>Longhini Alberta,</nobr> <nobr>Welle Michael C,</nobr> <nobr>Alenyà Guillem,</nobr> <nobr>Kragic Danica,</nobr> <nobr>Borràs Júlia</nobr> <br> <em>International Conference on Robotics and Automation (ICRA)</em>, 2024 <br> </div> <div style="line-height:50%;"> <br> </div> <div style="font-size:small"> <em> <a href="https://arxiv.org/pdf/2209.08996.pdf" rel="external nofollow noopener" target="_blank">[PDF]</a> <a href="javascript:showhide('bibgarcia2024standardization')">[Bibtex]</a> <a href="javascript:showhide('absgarcia2024standardization')">[Abstract]</a> </em> <div id="bibgarcia2024standardization" style="display:none"> <br> <blockquote> <div style="white-space: pre-wrap;">@article{garcia2024standardization, title={Standardization of Cloth Objects and its Relevance in Robotic Manipulation}, author={Garcia-Camacho, Irene and Longhini, Alberta and Welle, Michael and Aleny{\`a}, Guillem and Kragic, Danica and Borr{\`a}s, J{\'u}lia}, journal={arXiv preprint arXiv:2403.04608}, year={2024} } </div> </blockquote> </div> <div id="absgarcia2024standardization" style="display:none"> <br> The field of robotics faces inherent challenges in manipulating deformable objects, particularly in understanding and standardising fabric properties like elasticity, stiffness, and friction. While the significance of these properties is evident in the realm of cloth manipulation, accurately categorising and comprehending them in real-world applications remains elusive. This study sets out to address two primary objectives: (1) to provide a framework suitable for robotics applications to characterise cloth objects,, and (2) to study how these properties influence robotic manipulation tasks. Our preliminary results validate the framework's ability to characterise cloth properties and compare cloth sets, and reveal the influence that different properties have on the outcome of five manipulation primitives. We believe that, in general, results on the manipulation of clothes should be reported along with a better description of the garments used in the evaluation. This paper proposes a set of these measures. </div> </div> <br> </td> </tr> <tr> <td width="200" height="100"> <img src="../assets/images/EDONet.png" img="" width="250"> </td> <td> <h6><a href="https://arxiv.org/pdf/2209.08996.pdf" rel="external nofollow noopener" target="_blank">EDO-Net: Learning Elastic Properties of Deformable Objects from Graph Dynamics</a></h6> <div style="line-height:50%;"> <br> </div> <div style="font-size:medium"> <nobr>Alberta Longhini,</nobr> <nobr>Marco Moletta,</nobr> <nobr>Alfredo Reichlin,</nobr> <nobr>Michael C Welle,</nobr> <nobr>David Held,</nobr> <nobr>Zackory Erickson,</nobr> <nobr>Danica Kragic</nobr> <br> <em>International Conference on Robotics and Automation (ICRA)</em>, 2023 <br> </div> <div style="line-height:50%;"> <br> </div> <div style="font-size:small"> <em> <a href="https://arxiv.org/pdf/2209.08996.pdf" rel="external nofollow noopener" target="_blank">[PDF]</a> <a href="javascript:showhide('biblonghini2022edo')">[Bibtex]</a> <a href="javascript:showhide('abslonghini2022edo')">[Abstract]</a> </em> <div id="biblonghini2022edo" style="display:none"> <br> <blockquote> <div style="white-space: pre-wrap;">@article{longhini2022edo, title={EDO-Net: Learning Elastic Properties of Deformable Objects from Graph Dynamics}, author={Longhini*, Alberta and Moletta*, Marco and Reichlin, Alfredo and Welle, Michael C and Held, David and Erickson, Zackory and Kragic, Danica}, journal={arXiv preprint arXiv:2209.08996}, year={2022} } </div> </blockquote> </div> <div id="abslonghini2022edo" style="display:none"> <br> We study the problem of learning graph dynamics of deformable objects which generalize to unknown physical properties. In particular, we leverage a latent representation of elastic physical properties of cloth-like deformable objects which we explore through a pulling interaction. We propose EDO-Net (Elastic Deformable Object - Net), a model trained in a self-supervised fashion on a large variety of samples with different elastic properties. EDO-Net jointly learns an adaptation module, responsible for extracting a latent representation of the physical properties of the object, and a forwarddynamics module, which leverages the latent representation to predict future states of cloth-like objects, represented as graphs. We evaluate EDO-Net both in simulation and real world, assessing its capabilities of: 1) generalizing to unknown physical properties of cloth-like deformable objects, 2) transferring the learned representation to new downstream tasks. </div> </div> <br> </td> </tr> <tr> <td width="200" height="100"> <img src="../assets/images/EC.png" img="" width="250"> </td> <td> <h6><a href="https://arxiv.org/pdf/2209.05428.pdf" rel="external nofollow noopener" target="_blank">Elastic Context: Encoding Elasticity for Data-driven Models of Textiles</a></h6> <div style="line-height:50%;"> <br> </div> <div style="font-size:medium"> <nobr>Alberta Longhini,</nobr> <nobr>Marco Moletta,</nobr> <nobr>Alfredo Reichlin,</nobr> <nobr>Michael C Welle,</nobr> <nobr>Alexander Kravberg,</nobr> <nobr>Yufei Wang,</nobr> <nobr>David Held,</nobr> <nobr>Zackory Erickson,</nobr> <nobr>Danica Kragic</nobr> <br> <em>International Conference on Robotics and Automation (ICRA)</em>, 2023 <br> </div> <div style="line-height:50%;"> <br> </div> <div style="font-size:small"> <em> <a href="https://arxiv.org/pdf/2209.05428.pdf" rel="external nofollow noopener" target="_blank">[PDF]</a> <a href="javascript:showhide('biblonghini2022elastic')">[Bibtex]</a> <a href="javascript:showhide('abslonghini2022elastic')">[Abstract]</a> </em> <div id="biblonghini2022elastic" style="display:none"> <br> <blockquote> <div style="white-space: pre-wrap;">@article{longhini2022elastic, title={Elastic Context: Encoding Elasticity for Data-driven Models of Textiles}, author={Longhini, Alberta and Moletta, Marco and Reichlin, Alfredo and Welle, Michael C and Kravberg, Alexander and Wang, Yufei and Held, David and Erickson, Zackory and Kragic, Danica}, journal={arXiv preprint arXiv:2209.05428}, year={2022} } </div> </blockquote> </div> <div id="abslonghini2022elastic" style="display:none"> <br> Physical interaction with textiles, such as assistive dressing, relies on advanced dextreous capabilities. The underlying complexity in textile behavior when being pulled and stretched, is due to both the yarn material properties and the textile construction technique. Today, there are no commonly adopted and annotated datasets on which the various interaction or property identification methods are assessed. One important property that affects the interaction is material elasticity that results from both the yarn material and construction technique: these two are intertwined and, if not known a-priori, almost impossible to identify through sensing commonly available on robotic platforms. We introduce Elastic Context (EC), a concept that integrates various properties that affect elastic behavior, to enable a more effective physical interaction with textiles. The definition of EC relies on stress/strain curves commonly used in textile engineering, which we reformulated for robotic applications. We employ EC using Graph Neural Network (GNN) to learn generalized elastic behaviors of textiles. Furthermore, we explore the effect the dimension of the EC has on accurate force modeling of non-linear real-world elastic behaviors, highlighting the challenges of current robotic setups to sense textile properties. </div> </div> <br> </td> </tr> <tr> <td width="200" height="100"> <img src="../assets/images/DLO.gif" img="" width="250"> </td> <td> <h6><a href="https://physical-reasoning.github.io/assets/pdf/papers/10.pdf" rel="external nofollow noopener" target="_blank">DLO@Scale - A Large-Scale Meta Dataset for Learning Non-Rigid Object Pushing Dynamics</a></h6> <div style="line-height:50%;"> <br> </div> <div style="font-size:medium"> <nobr>Robert Gieselmann,</nobr> <nobr>Alberta Longhini,</nobr> <nobr>Alfredo Reichlin,</nobr> <nobr>Danica Kragic,</nobr> <nobr>Florian T. Pokorny</nobr> <br> <em>(Workshop on Physical Reasoning and Inductive Biases for the Real World, NeurIPS</em>, 2021 <br> </div> <div style="line-height:50%;"> <br> </div> <div style="font-size:small"> <em> <a href="https://physical-reasoning.github.io/assets/pdf/papers/10.pdf" rel="external nofollow noopener" target="_blank">[PDF]</a> <a href="javascript:showhide('biblonghini2022elastic')">[Bibtex]</a> <a href="javascript:showhide('abslonghini2022elastic')">[Abstract]</a> </em> <div id="biblonghini2022elastic" style="display:none"> <br> <blockquote> <div style="white-space: pre-wrap;">@article{gieselmann2021DLO, title={DLO@Scale - A Large-Scale Meta Dataset for Learning Non-Rigid Object Pushing Dynamics}, author={ Robert Gieselmann, Alberta Longhini, Alfredo Reichlin, Danica Kragic, Florian T. Pokorny}, journal={Workshop on Physical Reasoning and Inductive Biases for the Real World, NeurIPS}, year={2021} } </div> </blockquote> </div> <div id="abslonghini2022elastic" style="display:none"> <br> The ability to quickly understand our physical environment and make predictions about interacting objects is fundamental to us humans. To equip artificial agents with similar reasoning capabilities, machine learning can be used to approximate the underlying state dynamics of a system. In this regard, deep learning has gained much popularity but is relying on the availability of large-enough datasets. In this work, we present DLO@Scale, a new dataset for studying future state prediction in the context of multi-body deformable linear object pushing. It contains a large collection of 100 million simulated interactions enabling thorough statistical analysis and algorithmic benchmarks. Our data is generated using a high-fidelity physics engine which simulates complex mechanical phenomena such as elasticity, plastic deformation and friction. An important aspect is the large variation of the physical parameters making it suitable for testing meta learning algorithms. We describe DLO@Scale and present a first empirical evaluation using neural network baselines. More information and videos can be found at https://sites.google. com/view/dloscale. </div> </div> <br> </td> </tr> <tr> <td width="200" height="100"> <img src="../assets/images/Perveiving_workshop.png" img="" width="250"> </td> <td> <h6><a href="https://deformable-workshop.github.io/icra2021/spotlight/spot_perceiving_and_handling.pdf" rel="external nofollow noopener" target="_blank">Perceiving and Handling Textiles: a Robotics Perspective</a></h6> <div style="line-height:50%;"> <br> </div> <div style="font-size:medium"> <nobr>Alberta Longhini,</nobr> <nobr>Marco Moletta,</nobr> <nobr>Michael C Welle,</nobr> <nobr>Ioanna Mitsioni,</nobr> <nobr>Danica Kragic</nobr> <br> <em>Workshop on Representing and Manipulating Deformable Objects</em>, 2021 <br> </div> <div style="line-height:50%;"> <br> </div> <div style="font-size:small"> <em> <a href="https://deformable-workshop.github.io/icra2021/spotlight/spot_perceiving_and_handling.pdf" rel="external nofollow noopener" target="_blank">[PDF]</a> <a href="javascript:showhide('biblonghiniperceiving')">[Bibtex]</a> <a href="javascript:showhide('abslonghiniperceiving')">[Abstract]</a> </em> <div id="biblonghiniperceiving" style="display:none"> <br> <blockquote> <div style="white-space: pre-wrap;">@article{longhiniperceiving, title={Perceiving and Handling Textiles: a Robotics Perspective}, author={Longhini, Alberta and Moletta, Marco and Welle, Michael C and Mitsioni, Ioanna and Kragic, Danica} } </div> </blockquote> </div> <div id="abslonghiniperceiving" style="display:none"> <br> The ability to perceive and handle textiles is important for many applications in service and industrial robotics. We present and discuss some of the open scientific challenges in this area and how perception, planning and control can contribute to address them. </div> </div> <br> </td> </tr> <tr> <td width="200" height="100"> <img src="../assets/images/taxonomy.png" img="" width="250"> </td> <td> <h6><a href="https://arxiv.org/pdf/2103.09555.pdf" rel="external nofollow noopener" target="_blank">Textile Taxonomy and Classification Using Pulling and Twisting</a></h6> <div style="line-height:50%;"> <br> </div> <div style="font-size:medium"> <nobr>Alberta Longhini,</nobr> <nobr>Michael C Welle,</nobr> <nobr>Ioanna Mitsioni,</nobr> <nobr>Danica Kragic</nobr> <br> <em>International Conference on Intelligent RObots and Systems (IROS)</em>, 2021 <br> </div> <div style="line-height:50%;"> <br> </div> <div style="font-size:small"> <em> <a href="https://arxiv.org/pdf/2103.09555.pdf" rel="external nofollow noopener" target="_blank">[PDF]</a> <a href="javascript:showhide('biblonghini2021textile')">[Bibtex]</a> <a href="javascript:showhide('abslonghini2021textile')">[Abstract]</a> </em> <div id="biblonghini2021textile" style="display:none"> <br> <blockquote> <div style="white-space: pre-wrap;">@inproceedings{longhini2021textile, title={Textile taxonomy and classification using pulling and twisting}, author={Longhini, Alberta and Welle, Michael C and Mitsioni, Ioanna and Kragic, Danica}, booktitle={2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, pages={7564--7571}, year={2021}, organization={IEEE} } </div> </blockquote> </div> <div id="abslonghini2021textile" style="display:none"> <br> Identification of textile properties is an important milestone toward advanced robotic manipulation tasks that consider interaction with clothing items such as assisted dressing, laundry folding, automated sewing, textile recycling and reusing. Despite the abundance of work considering this class of deformable objects, many open problems remain. These relate to the choice and modelling of the sensory feedback as well as the control and planning of the interaction and manipulation strategies. Most importantly, there is no structured approach for studying and assessing different approaches that may bridge the gap between the robotics community and textile production industry. To this end, we outline a textile taxonomy considering fiber types and production methods, commonly used in textile industry. We devise datasets according to the taxonomy, and study how robotic actions, such as pulling and twisting of the textile samples, can be used for the classification. We also provide important insights from the perspective of visualization and interpretability of the gathered data. </div> </div> <br> </td> </tr> <tr> <td width="200" height="100"> <img src="../assets/images/TLD.png" img="" width="250"> </td> <td> <h6><a href="https://arxiv.org/pdf/2103.03520.pdf" rel="external nofollow noopener" target="_blank">Learning the tuned liquid damper dynamics by means of a robust EKF</a></h6> <div style="line-height:50%;"> <br> </div> <div style="font-size:medium"> <nobr>Alberta Longhini,</nobr> <nobr>Michele Perbellini,</nobr> <nobr>Stefano Gottardi,</nobr> <nobr>Shenglun Yi,</nobr> <nobr>Hao Liu,</nobr> <nobr>Mattia Zorzi</nobr> <br> <em>American Control Conference (ACC)</em>, 2021 <br> </div> <div style="line-height:50%;"> <br> </div> <div style="font-size:small"> <em> <a href="https://arxiv.org/pdf/2103.03520.pdf" rel="external nofollow noopener" target="_blank">[PDF]</a> <a href="javascript:showhide('biblonghini2021learning')">[Bibtex]</a> <a href="javascript:showhide('abslonghini2021learning')">[Abstract]</a> </em> <div id="biblonghini2021learning" style="display:none"> <br> <blockquote> <div style="white-space: pre-wrap;">@inproceedings{longhini2021learning, title={Learning the tuned liquid damper dynamics by means of a robust EKF}, author={Longhini, Alberta and Perbellini, Michele and Gottardi, Stefano and Yi, Shenglun and Liu, Hao and Zorzi, Mattia}, booktitle={2021 American Control Conference (ACC)}, pages={60--65}, year={2021}, organization={IEEE} } </div> </blockquote> </div> <div id="abslonghini2021learning" style="display:none"> <br> The tuned liquid dampers (TLD) technology is a feasible and cost-effective seismic design. In order to improve its efficiency it is fundamental to find accurate models describing their dynamic. A TLD system can be modeled through the Housner model and its parameters can be estimated by solving a nonlinear state estimation problem. We propose a robust extended Kalman filter which alleviates the model discretization and the fact that the noise process is not known. We test the effectiveness of the proposed approach by using some experimental data corresponding to two classical seismic waves, namely the El Centro wave and the Hachinohe wave. </div> </div> <br> </td> </tr> </table> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Alberta Longhini. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/al-folio/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/al-folio/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/al-folio/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/al-folio/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/al-folio/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/al-folio/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/al-folio/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/al-folio/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>